# ğŸ›ï¸ Legal Platform ReAct Agent API

A sophisticated FastAPI-based legal intelligence platform powered by **LlamaIndex ReAct Agents**, **Pinecone vector database**, and **OpenAI LLMs**. This system provides intelligent analysis for legal compliance, case research, and document management.

## ğŸš€ Key Features

### **Multi-Agent Intelligence System**
- **ğŸ” ReAct Agents**: Reasoning + Acting paradigm for intelligent decision making
- **ğŸ“‹ Compliance Agent**: FHIR compliance analysis and checklist generation
- **âš–ï¸ Legal Agent**: BNS law research with severity classification
- **ğŸ“„ Document Agent**: Intelligent document analysis and categorization
- **ğŸ“ Case Agent**: Similar case discovery and precedent analysis

### **Advanced Capabilities**
- **ğŸ¯ Intelligent Grid Population**: AI-powered data population for 4-grid dashboard
- **ğŸ”„ Real-time Streaming**: WebSocket support for live updates
- **ğŸ§  Multi-Document RAG**: Semantic search across legal knowledge bases
- **ğŸ“Š Structured Responses**: Pydantic models for type-safe API responses
- **âš¡ Parallel Processing**: Async agent execution for optimal performance

### **Legal Domain Expertise**
- **FHIR Compliance**: Medical-legal compliance tracking and validation
- **BNS Law Database**: Bharatiya Nyaya Sanhita legal reference system
- **Case Precedents**: Historical case analysis and similarity scoring
- **Document Intelligence**: Legal document classification and summarization

## Requirements
- Python 3.8+
- See `requirements.txt` for Python dependencies

## Local Development
1. Clone the repository and navigate to the project directory.
2. Create a `.env` file with your API keys:
   ```env
   OPENAI_API_KEY=your_openai_key
   PINECONE_API_KEY=your_pinecone_key
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Run the server locally:
   ```bash
   uvicorn query_api:app --reload
   ```

5. Test the API using the enhanced tester:
   ```bash
   streamlit run agent_tester.py
   ```

## Deployment (Render)
1. Push your code to a GitHub repository.
2. On [Render](https://render.com), create a new **Web Service** and connect your repo.
3. Set the following in Render's dashboard:
   - **Start Command:**
     ```
     uvicorn query_api:app --host 0.0.0.0 --port $PORT
     ```
   - **Environment Variables:**
     - `OPENAI_API_KEY` (required)
     - `PINECONE_API_KEY` (required)
4. Deploy and test your endpoints at the provided Render URL.

## .gitignore
Your `.gitignore` should contain at least:
```
.env
__pycache__/
```

## ğŸ”— API Endpoints

### **ğŸ¯ ReAct Agent Endpoints**

#### Master Dashboard Population
```http
POST /dashboard/populate
Content-Type: application/json

{
  "case_id": "CASE-2024-001",
  "case_context": "Medical malpractice case involving surgical complications",
  "user_role": "analyst",
  "jurisdiction": "Maharashtra"
}
```

#### Individual Grid Endpoints
- **ğŸ“‹ Compliance Grid**: `POST /grid/compliance`
- **âš–ï¸ Laws Grid**: `POST /grid/laws`
- **ğŸ“„ Documents Grid**: `POST /grid/documents`
- **ğŸ“ Cases Grid**: `POST /grid/cases`

#### Real-time Streaming
- **ğŸ”„ WebSocket**: `WS /dashboard/stream`

### **ğŸ’¬ Original Chat Endpoints**
- **Single Query**: `POST /query`
- **Multi-turn Chat**: `POST /chat`
- **Citizen Chat**: `POST /citizen_chat`
- **Streaming Chat**: `POST /citizen_chat_stream`

### **ğŸ¥ Health & Status**
- **Health Check**: `GET /health`
- **Agent Status**: `GET /agents/status`
- **API Info**: `GET /`

## ğŸ“š Usage Examples

### Dashboard Population
```python
import requests

response = requests.post("http://localhost:8000/dashboard/populate", json={
    "case_id": "CASE-2024-001",
    "case_context": "Medical malpractice case involving surgical complications at City Hospital",
    "user_role": "analyst",
    "jurisdiction": "Maharashtra"
})

dashboard_data = response.json()
print(f"Compliance: {dashboard_data['grid_1_compliance']['percentage']}% complete")
print(f"Found {len(dashboard_data['grid_2_laws']['laws'])} relevant laws")
```

### Individual Grid Testing
```python
# Test compliance grid
response = requests.post("http://localhost:8000/grid/compliance", json={
    "case_id": "CASE-2024-001",
    "context": "FHIR compliance for medical case"
})

compliance = response.json()
for item in compliance['checklist_items']:
    status = "âœ…" if item['status'] == 'completed' else "â³"
    print(f"{status} {item['item']}")
```

### WebSocket Streaming
```javascript
const ws = new WebSocket('ws://localhost:8000/dashboard/stream');

ws.onopen = function() {
    ws.send(JSON.stringify({
        "case_id": "CASE-2024-001",
        "case_context": "Medical malpractice case"
    }));
};

ws.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log(`Grid ${data.grid}: ${data.status}`);
};
```

## ğŸ§ª Testing

### Using the Enhanced Tester
1. Start the API server:
   ```bash
   uvicorn query_api:app --reload
   ```

2. Launch the test interface:
   ```bash
   streamlit run agent_tester.py
   ```

3. Test different sections:
   - **ğŸ  Dashboard Population**: Test the master endpoint
   - **ğŸ“‹ Individual Grids**: Test each grid separately
   - **ğŸ”„ Real-time Streaming**: WebSocket testing
   - **ğŸ’¬ Original Chat APIs**: Legacy chat endpoints
   - **ğŸ¥ Health & Status**: System health checks

### Using the Original Tester
```bash
streamlit run api_tester.py
```

## ğŸ—ï¸ Architecture

### **Agent System**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚    â”‚  Agent Manager   â”‚    â”‚  ReAct Agents   â”‚
â”‚   Endpoints     â”‚â”€â”€â”€â–¶â”‚  Orchestrator    â”‚â”€â”€â”€â–¶â”‚  - Compliance   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚  - Legal        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Documents    â”‚
                                                â”‚  - Cases        â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  LlamaIndex RAG  â”‚
                    â”‚  + Pinecone DB   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow**
1. **Request**: Client sends case context to dashboard endpoint
2. **Agent Dispatch**: Agent manager runs 4 specialized agents in parallel
3. **RAG Processing**: Each agent queries relevant knowledge bases
4. **Response Parsing**: Raw agent outputs parsed into structured responses
5. **Grid Population**: Frontend receives structured data for each grid

## ğŸ”§ Configuration

### Environment Variables
```env
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=quickstart
LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small
```

### Agent Configuration
Agents can be customized in `agents.py`:
- **System prompts** for specialized behavior
- **Tool selection** for different knowledge bases
- **Response modes** for different output formats
- `POST /citizen_chat_stream`

See `query_api.py` for details on request/response formats.

---

Feel free to open issues or PRs for improvements!
